{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c54c1af",
   "metadata": {},
   "source": [
    "# Simplified Features\n",
    "\n",
    "Within this section I'll take the data generated in the previous section and simplify the features used by the model. This section is important as I'd like to create a more user friendly model, at the expense of model accuracy. Simplifying, for instance, the soil types from probability of soil X,Y,Z to is_soil 'Clay'? will be beneficial to make the deployed model more useable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8d86d",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b221a136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/Users/ryan/miniconda3/envs/tf/lib/python3.9/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.25.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import pycaret\n",
    "from pycaret.regression import *\n",
    "from pycaret.regression import RegressionExperiment\n",
    "from pycaret.regression import get_config\n",
    "from pycaret.regression import save_model, load_model\n",
    "\n",
    "from pandas import json_normalize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9920aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ada1c",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ff1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/data_adj.pkl', 'rb') as f:\n",
    "    data_adj = pickle.load(f)\n",
    "with open('pickles/data_adj_unseen.pkl', 'rb') as f:\n",
    "    data_adj_unseen = pickle.load(f)\n",
    "with open('pickles/df_soil.pkl', 'rb') as f:\n",
    "    df_soil = pickle.load(f)\n",
    "with open('pickles/df_adj.pkl', 'rb') as f:\n",
    "    df_adj = pickle.load(f)\n",
    "with open('pickles/df_streamlit.pkl', 'rb') as f:\n",
    "    df_streamlit = pickle.load(f)   \n",
    "with open('pickles/data_subset.pkl', 'rb') as f:\n",
    "    data_subset = pickle.load(f)\n",
    "with open('pickles/data_subset.pkl', 'rb') as f:\n",
    "    data_subset = pickle.load(f)\n",
    "with open('pickles/combined_metrics.pkl', 'rb') as f:\n",
    "    combined_metrics = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78306ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_streamlit.pkl', 'rb') as f:\n",
    "    df_streamlit = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6f9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.concat([data_adj,data_adj_unseen],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67af1a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'city', 'start_year', 'end_year', 'rr?', 'length',\n",
       "       'tunnel_per', 'tunnel', 'elevated', 'at_grade', 'stations', 'max_speed',\n",
       "       'track_gauge', 'overhead?', 'cost', 'currency', 'year', 'ppp_rate',\n",
       "       'cost_real', 'cost_km', 'c_length', 'c_tunnel', 'anglo',\n",
       "       'inflation_index', 'cost_real_2021', 'cost_km_2021', 'duration',\n",
       "       'country_pop_den', 'region', 'sub_region', 'area_km', 'lat', 'lng',\n",
       "       'population', 'time_diff', 'calculated_population', 'city_density',\n",
       "       'per_below_line', 'reporting_gdp', 'wrb_class_name', 'wrb_class_value',\n",
       "       'prob_Acrisols', 'prob_Albeluvisols', 'prob_Alisols', 'prob_Andosols',\n",
       "       'prob_Arenosols', 'prob_Calcisols', 'prob_Cambisols', 'prob_Chernozems',\n",
       "       'prob_Cryosols', 'prob_Durisols', 'prob_Ferralsols', 'prob_Fluvisols',\n",
       "       'prob_Gleysols', 'prob_Gypsisols', 'prob_Histosols', 'prob_Kastanozems',\n",
       "       'prob_Leptosols', 'prob_Lixisols', 'prob_Luvisols', 'prob_Nitisols',\n",
       "       'prob_Phaeozems', 'prob_Planosols', 'prob_Plinthosols', 'prob_Podzols',\n",
       "       'prob_Regosols', 'prob_Solonchaks', 'prob_Solonetz', 'prob_Stagnosols',\n",
       "       'prob_Umbrisols', 'prob_Vertisols', 'elevation', 'tavg', 'tmin', 'tmax',\n",
       "       'prcp', 'land_cost_year', 'price_income_ratio', 'mortgage_perc_income',\n",
       "       'affordability_index', 'urban?', 'rental_yield', 'price_rent_ratio',\n",
       "       'union_density', 'stations_per_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place = df_adj[['country','city','length','stations','track_gauge','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596dcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.merge(df_user,df_place,how ='left',on=['stations','length','track_gauge','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356ca9a",
   "metadata": {},
   "source": [
    "## Feature Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4dfcf8",
   "metadata": {},
   "source": [
    "### Soil Types\n",
    "\n",
    "I'd like to simplify the World Reference Base for Soil Resources'soil class name' nomenclature used in the dataset by reducing each class name into a type of soil. \n",
    "\n",
    "Instead of AC Acrisol (low-activity clays, exchangeable Al > exchangeable base cations), I'd like to refine this to 'clays'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil_type = df_soil[['wrb_class_name','wrb_class_value']].drop_duplicates()\n",
    "df_soil_type.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fecb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.merge(df_user,df_soil_type,on=['wrb_class_value'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_probs = [\n",
    "    \"prob_Acrisols\", \"prob_Albeluvisols\", \"prob_Alisols\", \"prob_Andosols\",\n",
    "    \"prob_Arenosols\", \"prob_Calcisols\", \"prob_Cambisols\", \"prob_Chernozems\",\n",
    "    \"prob_Cryosols\", \"prob_Durisols\", \"prob_Ferralsols\", \"prob_Fluvisols\",\n",
    "    \"prob_Gleysols\", \"prob_Gypsisols\", \"prob_Histosols\", \"prob_Kastanozems\",\n",
    "    \"prob_Leptosols\", \"prob_Lixisols\", \"prob_Luvisols\", \"prob_Nitisols\",\n",
    "    \"prob_Phaeozems\", \"prob_Planosols\", \"prob_Plinthosols\", \"prob_Podzols\",\n",
    "    \"prob_Regosols\", \"prob_Solonchaks\", \"prob_Solonetz\", \"prob_Stagnosols\",\n",
    "    \"prob_Umbrisols\", \"prob_Vertisols\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384319d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(columns=soil_probs,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['wrb_class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_simplified_class(wrb_class_name):\n",
    "    organic = ['Histosols']\n",
    "    human_altered = ['Anthrosols', 'Technosols']\n",
    "    cold_climates = ['Cryosols', 'Leptosols']\n",
    "    mineral_rich = ['Andosols', 'Podzols', 'Plinthosols', 'Ferralsols','Gleysols']\n",
    "    high_altitude_or_shallow = ['Stagnosols', 'Nitisols', 'Regosols']\n",
    "    fertile = ['Chernozems', 'Kastanozems', 'Phaeozems', 'Umbrisols', 'Cambisols']\n",
    "    saline_arid = ['Arenosols','Durisols', 'Gypsisols', 'Calcisols', 'Planosols','Solonchaks','Solonetzs']\n",
    "    clay_dominant = ['Retisols', 'Acrisols', 'Lixisols', 'Alisols', 'Luvisols','Albeluvisols','Vertisols']\n",
    "    river_valleys = ['Fluvisols']\n",
    "    \n",
    "    if wrb_class_name in organic:\n",
    "        return 'Organic (Bogs & Peats)'\n",
    "    elif wrb_class_name in human_altered:\n",
    "        return 'Human-altered (Urban, Cut/Fill, Artifacts)'\n",
    "    elif wrb_class_name in cold_climates:\n",
    "        return 'Cold Climates (Permafrost, Rock Outcrops)'\n",
    "    elif wrb_class_name in mineral_rich:\n",
    "        return 'Environment Dependent (Wetlands, Volcanic Ash, Mineral Rich)'\n",
    "    elif wrb_class_name in high_altitude_or_shallow:\n",
    "        return 'High Altitude/Wet (Mountain, Swampy)'\n",
    "    elif wrb_class_name in fertile:\n",
    "        return 'Fertile/Agricultural (Grasslands, Food Bearing, Pasture)'\n",
    "    elif wrb_class_name in saline_arid:\n",
    "        return 'Saline/Arid (Desert Soils, High Salt Content)'\n",
    "    elif wrb_class_name in clay_dominant:\n",
    "        return 'Clay Dominant'\n",
    "    elif wrb_class_name in river_valleys:\n",
    "        return 'River Valleys/Deltas (River Sediments)'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "df_user['soil_type'] = df_user['wrb_class_name'].apply(map_to_simplified_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17598ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_user['soil_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(columns= ['wrb_class_name','wrb_class_value'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0655d3",
   "metadata": {},
   "source": [
    "### Track Gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['track_gauge'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauge_mapping(value):\n",
    "    if value == 0:\n",
    "        return 'monorail'\n",
    "    elif value == 1435:\n",
    "        return 'standard'\n",
    "    elif value < 1435:\n",
    "        return 'narrow'\n",
    "    else:\n",
    "        return 'wide'\n",
    "\n",
    "df_user['gauge_width'] = df_user['track_gauge'].apply(gauge_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"gauge_width\"\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22a82b",
   "metadata": {},
   "source": [
    "### City Population\n",
    "\n",
    "Instead of using population numbers, I'll redefine the population as 'city size' where the user will select from a range of qualitative options instead of specific populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.sort_values(by='calculated_population',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc38aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"calculated_population\"\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63335309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_user.sort_values(by='calculated_population',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_mapping(value):\n",
    "    if value < 250000:\n",
    "        return '<250k (small)'\n",
    "    elif (value >=250000) &(value<500000):\n",
    "        return '250k-500k (medium-small)'\n",
    "    elif (value >=500000) & (value<1000000):\n",
    "        return '500k-1M (medium)'\n",
    "    elif (value >=1000000) &(value<2000000):\n",
    "        return '1M-2M (medium-large)'\n",
    "    elif (value >=2000000) &(value<5000000):\n",
    "        return '2M-5M (large)'\n",
    "    elif (value >=5000000) &(value<10000000):\n",
    "        return '5M-10M (very large)'\n",
    "    elif (value >=10000000) &(value<15000000):\n",
    "        return '10M-15M (small Metropolis)'\n",
    "    else:\n",
    "        return '>15M (Metropolis)'\n",
    "\n",
    "df_user['city_size'] = df_user['calculated_population'].apply(pop_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"city_size\" \n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60ea68",
   "metadata": {},
   "source": [
    "#### Train Type\n",
    "\n",
    "Within the dataset, I make a distinction between different types of trains however I don't explicitely dicipher between different types of metros, i.e. subways and at-grade trams. I'll do that below using the tunnel_per feature and the max speed feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_type_mapping(row):\n",
    "    max_speed = row['max_speed']\n",
    "    tunnel_per = row['tunnel_per']\n",
    "    track_gauge = row['track_gauge']\n",
    "    elevated = row['elevated']\n",
    "    at_grade = row['at_grade']\n",
    "    length = row['length']\n",
    "\n",
    "    if (max_speed <= 60) & (tunnel_per == 0):\n",
    "        return 'tram'\n",
    "    elif (tunnel_per >.8):\n",
    "        return 'subway'\n",
    "    elif (track_gauge ==0):\n",
    "        return 'monorail'\n",
    "    elif (tunnel_per < 1) & (elevated > .8*length):\n",
    "        return 'elevated light rail'\n",
    "    else:\n",
    "        return 'light rail'\n",
    "\n",
    "df_user['train_type'] = df_user.apply(train_type_mapping,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fde804",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"train_type\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821bb0d",
   "metadata": {},
   "source": [
    "### Country Wealth\n",
    "\n",
    "In this feature, I'll combine the population and the GDP to create a GDP per capita. I'll then classify that GDP per capita into distinct categories, as defined by the World Economic Forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a024b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['gdp_cap'] = (df_user['reporting_gdp']*1000000)/df_user['calculated_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wealth_mapping(value):\n",
    "    if (value <= 1045):\n",
    "        return 'low-income'\n",
    "    elif (value > 1045) & (value < 4095):\n",
    "        return 'lower-middle income'\n",
    "    elif (value > 4096) & (value < 12695):\n",
    "        return 'upper-middle income'\n",
    "    else:\n",
    "        return 'high-income'\n",
    "\n",
    "df_user['country_income_class'] = df_user['gdp_cap'].apply(wealth_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"country_income_class\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b08d31",
   "metadata": {},
   "source": [
    "### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec26fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"elevation\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=True)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elevation_mapping(value):\n",
    "    if (value <= 200):\n",
    "        return 'Coastal'\n",
    "    elif (value > 200) & (value <= 1000):\n",
    "        return 'Mid-land'\n",
    "    elif (value > 1000) & (value <= 2500):\n",
    "        return 'High-land'\n",
    "    elif (value > 2500) & (value <= 3500):\n",
    "        return 'Mountainous'\n",
    "    else:\n",
    "        return 'High Altitude'\n",
    "\n",
    "df_user['elevation_class'] = df_user['elevation'].apply(elevation_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7aa699",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"elevation_class\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd367b54",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"prcp\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=True)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precipitation_mapping(value):\n",
    "    if value <= 10:\n",
    "        return 'Very-Arid'\n",
    "    elif (value > 10) & (value <= 20):\n",
    "        return 'Arid'\n",
    "    elif (value > 20) & (value <= 40):\n",
    "        return 'Semi-Arid'\n",
    "    elif (value > 40) & (value <= 60):\n",
    "        return 'Low-Moderate-Rainfall'\n",
    "    elif (value > 60) & (value <= 100):\n",
    "        return 'Moderate-Rainfall'\n",
    "    elif (value > 100) & (value <= 150):\n",
    "        return 'High-Moderate-Rainfall'\n",
    "    elif (value > 150) & (value <= 200):\n",
    "        return 'High-Rainfall'\n",
    "    elif (value > 200) & (value <= 250):\n",
    "        return 'Very-High-Rainfall'\n",
    "    else:\n",
    "        return 'Extreme-Rainfall/Tropical'\n",
    "\n",
    "df_user['precipitation_type'] = df_user['prcp'].apply(precipitation_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"precipitation_type\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a160d3",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5cca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_mapping(row):\n",
    "    avg_temp = row['tavg']\n",
    "    t_min = row['tmin']\n",
    "    t_max = row['tmax']\n",
    "\n",
    "    if avg_temp <= 5 and t_min >= -30 and t_max <= 10:\n",
    "        return 'Very Cold'\n",
    "    elif avg_temp <= 15 and t_min >= -20 and t_max <= 20:\n",
    "        return 'Cold/Cool'\n",
    "    elif avg_temp <= 25 and t_min >= -10 and t_max <= 30:\n",
    "        return 'Mild/Moderate'\n",
    "    elif avg_temp <= 33 and t_min >= 0 and t_max <= 33:\n",
    "        return 'Warm/Hot'\n",
    "    else:\n",
    "        return 'Very Hot or Extreme Heat'\n",
    "\n",
    "df_user['temperature_category'] = df_user.apply(temperature_mapping, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"temperature_category\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52173825",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_user['temperature_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f52ec",
   "metadata": {},
   "source": [
    "### Affordability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['affordability_index'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affordability_mapping(value):\n",
    "    if value == 0:\n",
    "        return 'Very Unaffordable'\n",
    "    elif value <= 1:\n",
    "        return 'Unaffordable'\n",
    "    elif value <= 5:\n",
    "        return 'Moderately Affordable'\n",
    "    elif value < 7:\n",
    "        return 'Affordable'\n",
    "    else:\n",
    "        return 'Highly Affordable'\n",
    "\n",
    "df_user['affordability'] = df_user['affordability_index'].apply(affordability_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"affordability\"\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782f171",
   "metadata": {},
   "source": [
    "### Union Prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d75b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(data=df_user, x=\"union_density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56543c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['union_density'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_density_mapping(value):\n",
    "    if value <= 13:\n",
    "        return 'Very Few/No Labor Unions'\n",
    "    elif value <= 14:\n",
    "        return 'Some Labor Unions'\n",
    "    elif value <= 30:\n",
    "        return 'Many Labor Unions'\n",
    "    else:\n",
    "        return 'Most People are Part of a Labor Union'\n",
    "\n",
    "df_user['union_prevalence'] = df_user['union_density'].apply(union_density_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"union_prevalence\"  \n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef3c64",
   "metadata": {},
   "source": [
    "### Poverty Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd38941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa8dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"per_below_line\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f155622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['per_below_line'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poverty_mapping(value):\n",
    "    if value <= 3:\n",
    "        return 'Very Little Poverty'\n",
    "    elif value <= 15:\n",
    "        return 'Little Poverty'\n",
    "    elif value <= 30:\n",
    "        return 'Some Poverty'\n",
    "    elif value <= 50:\n",
    "        return 'Very Impoverished'\n",
    "    else:\n",
    "        return 'Mostly Impoverished'\n",
    "\n",
    "df_user['poverty_rate'] = df_user['per_below_line'].apply(poverty_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"poverty_rate\"\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd71919",
   "metadata": {},
   "source": [
    "### City & Country Density\n",
    "\n",
    "Previously I had create a feature called 'urban', which was just a binary gate that indicated whether the city density was beyond a certain threshold. I'll expand that idea further here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"city_density\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=True)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['city_density'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_density_mapping(value):\n",
    "    if value <= 1523:\n",
    "        return 'Not Dense'\n",
    "    elif value <= 2779:\n",
    "        return 'Somewhat Dense'\n",
    "    elif value <= 5607:\n",
    "        return 'Dense'\n",
    "    else:\n",
    "        return 'Very Dense'\n",
    "\n",
    "df_user['city_density_type'] = df_user['city_density'].apply(city_density_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ddab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"city_density_type\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2742ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"country_pop_den\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=True)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['country_pop_den'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a17ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_density_mapping(value):\n",
    "    if value <= 114:\n",
    "        return 'Not Dense'\n",
    "    elif value <= 125:\n",
    "        return 'Marginally Dense'\n",
    "    elif value <= 150:\n",
    "        return 'Dense'\n",
    "    else:\n",
    "        return 'Very Dense'\n",
    "\n",
    "df_user['country_density_type'] = df_user['country_pop_den'].apply(country_density_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_plot = \"country_density_type\"  # Replace with the name of the column you want to plot\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_user[column_to_plot], kde=False)\n",
    "plt.title(f'Histogram of {column_to_plot}')\n",
    "plt.xticks(rotation=45)  # This line tilts the x labels by 45 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b91bae9",
   "metadata": {},
   "source": [
    "### Anglo?\n",
    "\n",
    "Currently the 'Anglo' category is a binary gate where a '1' indicates that the country is anglo and '0' indicates not. I want this to be more user friendly and so I'll convert these to 'yes' or 'no'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['anglo'] = np.where(df_user['anglo'] == 1,'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.rename(columns = {\"anglo\":\"anglo?\"},inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59747229",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_drop = ['country','city','rr?','tunnel_per',\n",
    "             'max_speed',\n",
    "             'track_gauge',\n",
    "             'overhead?','year','country_pop_den',\n",
    "             'area_km','population','calculated_population',\n",
    "             'city_density','per_below_line','reporting_gdp',\n",
    "             'elevation','tavg','tmin','tmax','prcp','gdp_cap',\n",
    "             'land_cost_year','price_income_ratio','mortgage_perc_income',\n",
    "             'affordability_index','urban?','rental_yield',\n",
    "             'price_rent_ratio','union_density','stations_per_km']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(columns = user_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a803ab",
   "metadata": {},
   "source": [
    "### Simplified Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_user.sample(frac=0.8, random_state=786)\n",
    "data_unseen = df_user.drop(data.index)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = ['length','tunnel','elevated','at_grade','duration',]\n",
    "cat_feats =  [\"region\", \"sub_region\", \"soil_type\", \"gauge_width\", \n",
    "    \"city_size\", \"train_type\", \n",
    "    \"country_income_class\", \"elevation_class\", \"precipitation_type\", \n",
    "    \"temperature_category\", \"affordability\", \"union_prevalence\",\n",
    "    \"poverty_rate\", \"city_density_type\", \"country_density_type\",\"anglo?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ff85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data,\n",
    "          target = 'cost_real_2021',\n",
    "          categorical_features= cat_feats,\n",
    "          numeric_features= cont_feats,\n",
    "          normalize = True,\n",
    "          normalize_method = 'zscore',\n",
    "          verbose = False,\n",
    "          feature_selection = False,\n",
    "          low_variance_threshold = 0.1,\n",
    "          pca = False, \n",
    "          pca_components = 30,\n",
    "          remove_multicollinearity = False,\n",
    "          multicollinearity_threshold = 0.3,\n",
    "          memory= False,\n",
    "          system_log= False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(exclude = ['lar','lr','llar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3ce6a",
   "metadata": {},
   "source": [
    "#### Individual Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbd4f5",
   "metadata": {},
   "source": [
    "###### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = create_model('catboost')\n",
    "param_grid_cat = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Learning rate.\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 10],  # Depth limit.\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],  # Coefficient at the L2 regularization term of weights for leaf value.\n",
    "    'bagging_temperature': [0.2, 0.5, 0.8, 1.0],  # The settings of the Bayesian bootstrap during training.\n",
    "    'border_count': [32, 64, 128, 255],  # The number of splits for numerical features.\n",
    "    'iterations': [50, 100, 200, 300],  # The maximum number of trees to be trained.\n",
    "    'loss_function': ['RMSE', 'Logloss', 'MultiClass'],  # Objective function.\n",
    "    'random_strength': [0.5, 1, 2, 3],  # The amount of randomness to use for scoring splits.\n",
    "    'boosting_type': ['Ordered', 'Plain'],  # Boosting type implementation.\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],  # Sample rate for bagging.\n",
    "    'rsm': [0.5, 0.7, 0.9, 1.0],  # (Equivalent to colsample_bytree in XGBoost) The percentage of features to use at each split selection.\n",
    "    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']  # Control the way new splits are added to the tree.\n",
    "}\n",
    "cat_tuned = tune_model(\n",
    "    cat,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_cat,\n",
    "    choose_better = False\n",
    ")\n",
    "predict_model(cat_tuned, data=data_unseen)\n",
    "cat_bagged = cat_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d175f18",
   "metadata": {},
   "source": [
    "###### ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ecd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "et = create_model('et')\n",
    "param_grid_et = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],  # Set bootstrap option. Default for ExtraTrees is False, but you can experiment with True.\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "et_tuned = tune_model(\n",
    "    et,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_et,\n",
    "    choose_better = False\n",
    ")\n",
    "predictions = predict_model(et_tuned, data=data_unseen)\n",
    "et_bagged = ensemble_model(et_tuned,method = 'Bagging',fold = 10,n_estimators = 100, choose_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676bae5",
   "metadata": {},
   "source": [
    "###### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "light = create_model('lightgbm')\n",
    "param_grid_light = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [31, 62, 127, 255],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10, -1],  # -1 means no limit.\n",
    "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'objective': ['regression', 'binary', 'multiclass'],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.5, 1],\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "}\n",
    "light_tuned = tune_model(\n",
    "    light,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_light,\n",
    "    choose_better = False\n",
    ")\n",
    "predictions = predict_model(light_tuned, data=data_unseen)\n",
    "light_bagged = ensemble_model(light_tuned,method = 'Bagging',fold = 10,n_estimators = 100, choose_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd465273",
   "metadata": {},
   "source": [
    "### Blended Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_user = blend_models([cat_bagged,et])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(blended_user, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(blended_user, plot = 'residuals_interactive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed6f1f",
   "metadata": {},
   "source": [
    "### Cooks Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8836f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(df_user.drop(columns=['cost_real_2021', 'region', 'sub_region']), drop_first=True)\n",
    "X_encoded['Intercept'] = 1\n",
    "X_encoded = X_encoded[['Intercept'] + [col for col in X_encoded if col != 'Intercept']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = X_encoded.values @ np.linalg.inv(X_encoded.values.T @ X_encoded.values) @ X_encoded.values.T\n",
    "leverage = np.diag(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5114d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['leverage'] = leverage\n",
    "df_user.sort_values(by='leverage',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e778cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_seen = predict_model(blended_user, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['residuals'] = predictions_seen['cost_real_2021'] - predictions_seen['prediction_label']\n",
    "mean_res = np.mean(df_user['residuals'])\n",
    "std_res = np.std(df_user['residuals'])\n",
    "\n",
    "df_user['standardized_residuals'] = (df_user['residuals'] - mean_res) / std_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X_encoded.shape[1]\n",
    "mse = np.mean(df_user['residuals'] ** 2)\n",
    "df_user['cooks_distance'] = (df_user['residuals'] ** 2 / (p * mse)) * (df_user['leverage'] / (1 - df_user['leverage']) ** 2)\n",
    "df_user.sort_values(by='cooks_distance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bd0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_user.shape[0]\n",
    "threshold = 4/n\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243307d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_outliers = df_user[df_user['cooks_distance']>threshold].sort_values(by='cooks_distance',ascending=False)\n",
    "cooks_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f33cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_outliers = df_user[df_user['cooks_distance']>threshold].sort_values(by='cooks_distance',ascending=False).index\n",
    "len(cooks_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(index = cooks_outliers,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.sort_values(by='standardized_residuals',ascending=False,key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eada9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res = df_user[abs(df_user['standardized_residuals'])> 2].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bea490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(index = high_res,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b8ac3",
   "metadata": {},
   "source": [
    "### Re-Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf079a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(columns =['cooks_distance','standardized_residuals','residuals','leverage'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_user.sample(frac=0.8, random_state=786)\n",
    "data_unseen = df_user.drop(data.index)\n",
    "\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ece69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data_unseen.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feats = ['length','tunnel','elevated','at_grade','duration',]\n",
    "cat_feats =  [\"region\", \"sub_region\", \"soil_type\", \"gauge_width\", \n",
    "    \"city_size\", \"train_type\", \n",
    "    \"country_income_class\", \"elevation_class\", \"precipitation_type\", \n",
    "    \"temperature_category\", \"affordability\", \"union_prevalence\",\n",
    "    \"poverty_rate\", \"city_density_type\", \"country_density_type\",\"anglo?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3039e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data,\n",
    "          target = 'cost_real_2021',\n",
    "          categorical_features= cat_feats,\n",
    "          numeric_features= cont_feats,\n",
    "          normalize = True,\n",
    "          normalize_method = 'zscore',\n",
    "          verbose = False,\n",
    "          feature_selection = False,\n",
    "          low_variance_threshold = 0.1,\n",
    "          pca = False, \n",
    "          pca_components = 30,\n",
    "          remove_multicollinearity = False,\n",
    "          multicollinearity_threshold = 0.3,\n",
    "          imputation_type= 'iterative',\n",
    "          categorical_imputation='mode',\n",
    "          numeric_imputation = 'mode',\n",
    "          memory= False,\n",
    "          system_log= False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(exclude = ['lar','knn','dt','ada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3324dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = create_model('catboost')\n",
    "param_grid_cat = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Learning rate.\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 10],  # Depth limit.\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],  # Coefficient at the L2 regularization term of weights for leaf value.\n",
    "    'bagging_temperature': [0.2, 0.5, 0.8, 1.0],  # The settings of the Bayesian bootstrap during training.\n",
    "    'border_count': [32, 64, 128, 255],  # The number of splits for numerical features.\n",
    "    'iterations': [50, 100, 200, 300],  # The maximum number of trees to be trained.\n",
    "    'loss_function': ['RMSE', 'Logloss', 'MultiClass'],  # Objective function.\n",
    "    'random_strength': [0.5, 1, 2, 3],  # The amount of randomness to use for scoring splits.\n",
    "    'boosting_type': ['Ordered', 'Plain'],  # Boosting type implementation.\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],  # Sample rate for bagging.\n",
    "    'rsm': [0.5, 0.7, 0.9, 1.0],  # (Equivalent to colsample_bytree in XGBoost) The percentage of features to use at each split selection.\n",
    "    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']  # Control the way new splits are added to the tree.\n",
    "}\n",
    "cat_tuned = tune_model(\n",
    "    cat,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_cat,\n",
    "    choose_better = False\n",
    ")\n",
    "predict_model(cat_tuned, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd27891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "et = create_model('et')\n",
    "param_grid_et = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],  # Set bootstrap option. Default for ExtraTrees is False, but you can experiment with True.\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "et_tuned = tune_model(\n",
    "    et,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_et,\n",
    "    choose_better = False\n",
    ")\n",
    "predictions = predict_model(et_tuned, data=data_unseen)\n",
    "et_bagged = ensemble_model(et_tuned,method = 'Bagging',fold = 10,n_estimators = 100, choose_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef6513",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "light = create_model('lightgbm')\n",
    "param_grid_light = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [31, 62, 127, 255],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10, -1],  # -1 means no limit.\n",
    "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'objective': ['regression', 'binary', 'multiclass'],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.5, 1],\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "}\n",
    "light_tuned = tune_model(\n",
    "    light,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_light,\n",
    "    choose_better = False\n",
    ")\n",
    "predictions = predict_model(light_tuned, data=data_unseen)\n",
    "light_bagged = ensemble_model(light_tuned,method = 'Bagging',fold = 10,n_estimators = 100, choose_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eb9552",
   "metadata": {},
   "source": [
    "### Blended Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc57042",
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_user_reduced = blend_models([cat,light_bagged,et])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0080a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_blended = predict_model(blended_user_reduced, data=data_unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22956b4",
   "metadata": {},
   "source": [
    "#### Tuning Blended Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae96fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blended_user_tuned = blend_models([cat,light_bagged,et],weights =[.7,.15,.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tuned = predict_model(blended_user_tuned, data=data_unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123c12e",
   "metadata": {},
   "source": [
    "### Finalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_user_model = finalize_model(blended_user_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4925df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_user = predict_model(finalized_user_model, data=data_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(blended_user_tuned, plot = 'msa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b539c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(light, plot = 'pfi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6ec6b",
   "metadata": {},
   "source": [
    "### SHAP Plot (in Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.get_dummies(data, columns=cat_feats)\n",
    "data_unseen_encoded = pd.get_dummies(data_unseen, columns=cat_feats)\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = set(data_encoded.columns) - set(data_unseen_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    data_unseen_encoded[c] = 0\n",
    "\n",
    "data_unseen_encoded = data_unseen_encoded[data_encoded.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d5c33",
   "metadata": {},
   "source": [
    "#### Model for SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2093802",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data_encoded,\n",
    "          target = 'cost_real_2021',\n",
    "          normalize = False,\n",
    "          normalize_method = 'zscore',\n",
    "          verbose = False,\n",
    "          memory= False,\n",
    "          system_log= False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_encoded = create_model('lightgbm')\n",
    "param_grid_light = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [31, 62, 127, 255],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10, -1],  # -1 means no limit.\n",
    "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],\n",
    "    'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'objective': ['regression', 'binary', 'multiclass'],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.5, 1],\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "}\n",
    "light_tuned_encoded = tune_model(\n",
    "    light,\n",
    "    fold = 10,\n",
    "    n_iter = 50,\n",
    "    custom_grid = param_grid_light,\n",
    "    choose_better = False\n",
    ")\n",
    "predictions = predict_model(light_tuned_encoded, data=data_unseen_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc12378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = get_config('X')\n",
    "explainer = shap.TreeExplainer(light_tuned_encoded)\n",
    "shap_values = explainer.shap_values(X_transformed)\n",
    "y_pred = predictions['prediction_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(shap_values, columns=X_transformed.columns)\n",
    "df_plot_melted = df_plot.melt(var_name=\"Feature\", value_name=\"SHAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e540f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times = df_plot_melted.shape[0] // y_pred.shape[0]\n",
    "remainder = df_plot_melted.shape[0] % y_pred.shape[0]\n",
    "new_tiled_array = np.concatenate([np.tile(y_pred, repeat_times), y_pred[:remainder]])\n",
    "df_plot_melted[\"predictions\"] = new_tiled_array\n",
    "\n",
    "# Aggregate and sort SHAP values\n",
    "agg_shap_total = df_plot_melted.groupby('Feature').agg({'SHAP': 'sum'}).reset_index()\n",
    "agg_shap_total = agg_shap_total.sort_values(by='SHAP', ascending=False)\n",
    "\n",
    "# Get the top 10 features based on total SHAP\n",
    "top_features = agg_shap_total['Feature'].head(10).tolist()\n",
    "df_plot_melted = df_plot_melted[df_plot_melted['Feature'].isin(top_features)]\n",
    "\n",
    "# Sort by SHAP value and calculate size\n",
    "df_plot_melted = df_plot_melted.sort_values(by=\"SHAP\", key=abs, ascending=True)\n",
    "df_plot_melted[\"size\"] = df_plot_melted[\"SHAP\"].abs()\n",
    "df_plot_melted[\"difference\"] = abs(df_plot_melted[\"predictions\"]+df_plot_melted[\"SHAP\"])\n",
    "\n",
    "shap_range = df_plot_melted.groupby('Feature')['SHAP'].agg(lambda x: x.max() - x.min()).reset_index()\n",
    "shap_range.columns = ['Feature', 'SHAP_Range']\n",
    "\n",
    "# Merge this with the main dataframe\n",
    "df_plot_melted = df_plot_melted.merge(shap_range, on='Feature')\n",
    "df_plot_melted['abs_avg'] = np.mean(abs(df_plot_melted['SHAP']))\n",
    "# Sort by SHAP range\n",
    "df_plot_melted = df_plot_melted.sort_values(by=\"abs_avg\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_plot_melted, x='SHAP', y='Feature', color='SHAP', size='difference', \n",
    "                 color_continuous_scale='plasma', height=800, width=800)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=True, gridcolor='WhiteSmoke', zerolinecolor='Gainsboro'),\n",
    "    yaxis=dict(showgrid=True, gridcolor='WhiteSmoke', zerolinecolor='Gainsboro'),\n",
    "    plot_bgcolor='white',\n",
    "    boxgap=1\n",
    ")\n",
    "fig.update_traces(marker=dict(line=dict(width=0)))\n",
    "\n",
    "# Save and show plot\n",
    "fig.write_html('plots/plotly_beeswarm_top10.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab21c6",
   "metadata": {},
   "source": [
    "### Importances Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620da649",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = light_tuned_encoded.feature_importances_\n",
    "feature_names = light_tuned_encoded.feature_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = importances.argsort()[-10::]\n",
    "feature_names_array = np.array(feature_names)\n",
    "sorted_names = feature_names_array[sorted_idx]\n",
    "greyish_white = '#D0D0D0'\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(y=sorted_names, \n",
    "           x=importances[sorted_idx], \n",
    "           orientation='h', \n",
    "           text=sorted_names,\n",
    "#            textfont=dict(color=greyish_white),\n",
    "           textposition='outside',\n",
    "           marker={'color': importances[sorted_idx],\n",
    "                   'colorscale': 'Viridis_r'})\n",
    "])\n",
    "fig.update_layout(\n",
    "    title='Feature Importances',\n",
    "#     title_font=dict(color=greyish_white),\n",
    "    yaxis_title='Features',\n",
    "#     yaxis_title_font=dict(color=greyish_white),  # Changes the y-axis title font color\n",
    "    xaxis_title='Importance',\n",
    "#     xaxis_title_font=dict(color=greyish_white),  # Changes the x-axis title font color\n",
    "    yaxis_showticklabels=False,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    xaxis=dict(\n",
    "        range=[0, 1100]  # Set your desired maximum value here\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.write_html(\"plots/importances_top10.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab22af",
   "metadata": {},
   "source": [
    "### Summary of Model Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\n",
    "    'Model': ['User Model'],\n",
    "    'Version': ['M_E1'],\n",
    "    'Dataset': ['df_user'],\n",
    "    'MAE': [475.0987],\n",
    "    'MSE': [652524.7350],\n",
    "    'RMSE': [807.7900],\n",
    "    'R2': [0.8952],\n",
    "    'RMSLE': [0.3213],\n",
    "    'MAPE': [0.2575]\n",
    "}\n",
    "\n",
    "new_metrics = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f84409",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics = combined_metrics.append(new_metrics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674ee32",
   "metadata": {},
   "source": [
    "### Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298664af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_user = data\n",
    "data_user_unseen = data_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9743d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_user.pkl', 'wb') as f:\n",
    "    pickle.dump(df_user, f)\n",
    "with open('pickles/data_user.pkl', 'wb') as f:\n",
    "    pickle.dump(data_user, f)\n",
    "with open('pickles/data_user_unseen.pkl', 'wb') as f:\n",
    "    pickle.dump(data_user_unseen, f)\n",
    "with open('pickles/combined_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_metrics, f)\n",
    "with open('pickles/df_streamlit.pkl', 'wb') as f:\n",
    "    pickle.dump(df_streamlit, f)\n",
    "with open('pickles/df_plot_melted.pkl', 'wb') as f:\n",
    "    pickle.dump(df_plot_melted, f)\n",
    "with open('pickles/predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)\n",
    "with open('pickles/predictions_user.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions_user, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71775b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(blended_user_tuned, 'models/blended_user_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcba71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model(finalized_user_model, 'models/finalized_user_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3c4e0",
   "metadata": {},
   "source": [
    "### Pickling the Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(finalized_user_model, open('models/finalized_user_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8b08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(finalized_user_model, 'finalized_user_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f396601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
